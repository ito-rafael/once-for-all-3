{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OFA³: Automatic Selection of the Best Non-dominated Sub-networks for Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Description**: \n",
    "  - This Jupyter notebook works as a preparation for the OFA³ search. \n",
    "  - We first load the 100 models obtained from the output of the OFA² search (file \"ofa2_nsga2.pickle\"). \n",
    "  - Then we take each model and evaluate them on a subset of the training set (50k images) of the ILSVRC dataset (ImageNet-1k). \n",
    "  - The output of this notebook provides two tables for each model (200 tables in total):\n",
    "    - \"OFA2_model_XXX_class.csv\": table containing the top-5 predicted classes of the model.\n",
    "    - \"OFA2_model_XXX_prob.csv\": table containing the respective probabilities.\n",
    "  - The directory that files will be saved is \"ofa2_models_output\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Author**: TBA (hidden due to blind review)\n",
    "- **email**: TBA (hidden due to blind review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **arXiv link**: TBA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q -r requirements.txt\n",
    "!pip install -q \\\n",
    "    numpy       \\\n",
    "    torch       \\\n",
    "    torchvision \\\n",
    "    ofa2        \\\n",
    "    tqdm        \\\n",
    "    matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# AI/ML/NN\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "# OFA/OFA²\n",
    "from ofa2.model_zoo import ofa_net\n",
    "from ofa2.imagenet_classification.elastic_nn.utils import set_running_statistics\n",
    "from ofa2.utils import AverageMeter#, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seeds for reproducibility\n",
    "random_seed = 1\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU.\n"
     ]
    }
   ],
   "source": [
    "# set device to use GPU or CPU\n",
    "cuda_available = torch.cuda.is_available()\n",
    "if cuda_available:\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    print(\"Using GPU.\")\n",
    "else:\n",
    "    print(\"Using CPU.\")\n",
    "#cuda0 = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rotKYovR6HsU",
    "outputId": "31a14141-3609-490e-abab-6ba9fef5ef5a",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ImageNet Full\n",
    "imagenet_data_path = \"~/dataset/imagenet/\"\n",
    "#----------------------------\n",
    "# ImageNet subset\n",
    "#imagenet_data_path = \"~/dataset/imagenet_1k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ofa_network = ofa_net(\"ofa_mbv3_d234_e346_k357_w1.2\", pretrained=True)\n",
    "# ofa_network2 = torch.load(model_dir='~/model/ofa_mbv3_d234_e346_k357_w1.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Ksze_r6G6HsV",
    "outputId": "d5b0e106-b7dc-4108-e9cb-f8287776bc18"
   },
   "outputs": [],
   "source": [
    "# The following function build the data transforms for test\n",
    "def build_val_transform(size):\n",
    "    return transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(int(math.ceil(size / 0.875))),\n",
    "            transforms.CenterCrop(size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this dataloader is for the training set --> used to generate probability table\n",
    "#data_loader_train = torch.utils.data.DataLoader(\n",
    "#    datasets.ImageFolder(\n",
    "#        root=os.path.join(imagenet_data_path, \"train\"), transform=build_val_transform(224)\n",
    "#    ),\n",
    "#    batch_size=4_096, # evaluation batch size\n",
    "#    shuffle=False,    # evaluation only\n",
    "#    num_workers=16,   # number of workers for the data loader\n",
    "#    pin_memory=True,\n",
    "#    drop_last=False,\n",
    "#)\n",
    "#print(\"The ImageNet dataloader for the training set is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ImageNet dataloader for the training set is ready.\n"
     ]
    }
   ],
   "source": [
    "# this dataloader is for the 50k subset of the training set --> used to generate probability table\n",
    "data_loader_train_subset = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(root=os.path.join(imagenet_data_path, \"train_subset_50k\"), transform=build_val_transform(224)),\n",
    "    batch_size=1_024, # evaluation batch size\n",
    "    shuffle=False,    # evaluation only\n",
    "    num_workers=4,    # number of workers for the data loader\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    ")\n",
    "print(\"The ImageNet dataloader for the training set is ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load results from OFA²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ofa2_nsga2.pickle', 'rb') as f:\n",
    "    ofa2_nsga2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_evaluate_ofa_subnet(\n",
    "    filename, ofa_net, path, net_config, data_loader, batch_size, device=\"cuda:0\"\n",
    "):\n",
    "    assert \"ks\" in net_config and \"d\" in net_config and \"e\" in net_config\n",
    "    assert (\n",
    "        len(net_config[\"ks\"]) == 20\n",
    "        and len(net_config[\"e\"]) == 20\n",
    "        and len(net_config[\"d\"]) == 5\n",
    "    )\n",
    "    ofa_net.set_active_subnet(ks=net_config[\"ks\"], d=net_config[\"d\"], e=net_config[\"e\"])\n",
    "    subnet = ofa_net.get_active_subnet().to(device)\n",
    "    calib_bn(subnet, path, net_config[\"r\"][0], batch_size)\n",
    "    top1 = validate(filename, subnet, path, net_config[\"r\"][0], data_loader, batch_size, device)\n",
    "    return top1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calib_bn(net, path, image_size, batch_size, num_images=2000):\n",
    "    # print('Creating dataloader for resetting BN running statistics...')\n",
    "    dataset = datasets.ImageFolder(\n",
    "        os.path.join(path, \"train\"),\n",
    "        transforms.Compose(\n",
    "            [\n",
    "                transforms.RandomResizedCrop(image_size),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ColorJitter(brightness=32.0 / 255.0, saturation=0.5),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "                ),\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "    chosen_indexes = np.random.choice(list(range(len(dataset))), num_images)\n",
    "    sub_sampler = torch.utils.data.sampler.SubsetRandomSampler(chosen_indexes)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        sampler=sub_sampler,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    # print('Resetting BN running statistics (this may take 10-20 seconds)...')\n",
    "    set_running_statistics(net, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from: once-for-all/ofa/utils/common_tools.py\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    softmax = torch.nn.functional.softmax(output, dim=1)\n",
    "    # prob, pred = softmax.topk(maxk, 1, True, True)\n",
    "    prob, _ = softmax.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.reshape(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res, pred.t(), prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(filename, net, path, image_size, data_loader, batch_size=100, device=\"cuda:0\"):\n",
    "    if \"cuda\" in device:\n",
    "        net = torch.nn.DataParallel(net).to(device)\n",
    "    else:\n",
    "        net = net.to(device)\n",
    "\n",
    "    data_loader.dataset.transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(int(math.ceil(image_size / 0.875))),\n",
    "            transforms.CenterCrop(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    net.eval()\n",
    "    net = net.to(device)\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=len(data_loader), desc=\"Validate\") as t:\n",
    "            for i, (images, labels) in enumerate(data_loader):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                # compute output\n",
    "                output = net(images)\n",
    "                loss = criterion(output, labels)\n",
    "                #-----------------------------------------------------\n",
    "                # measure accuracy and record loss\n",
    "                res, pred, prob = accuracy(output, labels, topk=(1, 5))\n",
    "                acc1 = res[0]\n",
    "                acc5 = res[1]\n",
    "                # save to CSV\n",
    "                if filename is not None:\n",
    "                    # print(f'{acc1=}, {acc5=}, {pred}, {labels=}')\n",
    "                    labels_t = labels.t().unsqueeze(dim=1)\n",
    "                    topk_classification = torch.cat((pred, labels_t), dim=1)\n",
    "                    # cast to DataFrame\n",
    "                    topk_df = pd.DataFrame(topk_classification.cpu())\n",
    "                    topk_df.to_csv(filename + '_class.csv', mode='a', header=False, index=False)\n",
    "                    # probability\n",
    "                    topk_prob = pd.DataFrame(prob.cpu())\n",
    "                    topk_prob.to_csv(filename + '_prob.csv', encoding='utf-8', mode='a', header=False, index=False)\n",
    "                #-----------------------------------------------------\n",
    "                                \n",
    "                losses.update(loss.item(), images.size(0))\n",
    "                top1.update(acc1[0].item(), images.size(0))\n",
    "                top5.update(acc5[0].item(), images.size(0))\n",
    "                t.set_postfix(\n",
    "                    {\n",
    "                        \"loss\": losses.avg,\n",
    "                        \"top1\": top1.avg,\n",
    "                        \"top5\": top5.avg,\n",
    "                        \"img_size\": images.size(2),\n",
    "                    }\n",
    "                )\n",
    "                t.update(1)\n",
    "\n",
    "    print(\n",
    "        \"Results: loss=%.5f,\\t top1=%.1f,\\t top5=%.1f\"\n",
    "        % (losses.avg, top1.avg, top5.avg)\n",
    "    )\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def individual_to_arch(population, n_blocks):\n",
    "    archs = []\n",
    "    for individual in population:\n",
    "        archs.append(\n",
    "            {\n",
    "                \"ks\": individual[0:n_blocks],\n",
    "                \"e\": individual[n_blocks : 2 * n_blocks],\n",
    "                \"d\": individual[2 * n_blocks : -1],\n",
    "                \"r\": individual[-1:],\n",
    "            }\n",
    "        )\n",
    "    return archs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def individual_to_ofa(model):\n",
    "    # insert wid\n",
    "    model['wid'] = None\n",
    "    # cast back from NumPy to list\n",
    "    model['ks'] = model['ks'].tolist()\n",
    "    model['e'] = model['e'].tolist()\n",
    "    model['d'] = model['d'].tolist()\n",
    "    model['r'] = model['r'].tolist()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate probability table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:02<00:00,  1.28s/it, loss=0.756, top1=83.3, top5=96.6, img_size=160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.75556,\t top1=83.3,\t top5=96.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:02<00:00,  1.28s/it, loss=0.76, top1=83.5, top5=96.7, img_size=160] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.76027,\t top1=83.5,\t top5=96.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:01<00:00,  1.25s/it, loss=0.734, top1=83.9, top5=96.9, img_size=160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.73435,\t top1=83.9,\t top5=96.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:01<00:00,  1.25s/it, loss=0.723, top1=84, top5=96.9, img_size=160]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.72279,\t top1=84.0,\t top5=96.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:02<00:00,  1.28s/it, loss=0.711, top1=84.5, top5=96.9, img_size=160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.71083,\t top1=84.5,\t top5=96.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:01<00:00,  1.26s/it, loss=0.692, top1=84.9, top5=97.2, img_size=160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.69196,\t top1=84.9,\t top5=97.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:02<00:00,  1.28s/it, loss=0.689, top1=84.9, top5=97.2, img_size=160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.68926,\t top1=84.9,\t top5=97.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:00<00:00,  1.23s/it, loss=0.675, top1=85.2, top5=97.3, img_size=160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.67500,\t top1=85.2,\t top5=97.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:03<00:00,  1.29s/it, loss=0.674, top1=85.2, top5=97.3, img_size=160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.67382,\t top1=85.2,\t top5=97.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:00<00:00,  1.23s/it, loss=0.653, top1=85.6, top5=97.4, img_size=160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.65328,\t top1=85.6,\t top5=97.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:02<00:00,  1.28s/it, loss=0.658, top1=85.6, top5=97.4, img_size=160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.65830,\t top1=85.6,\t top5=97.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:11<00:00,  1.46s/it, loss=0.638, top1=86.1, top5=97.6, img_size=160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.63768,\t top1=86.1,\t top5=97.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:00<00:00,  1.24s/it, loss=0.64, top1=86.2, top5=97.6, img_size=160] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.64032,\t top1=86.2,\t top5=97.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:01<00:00,  1.25s/it, loss=0.632, top1=86.2, top5=97.7, img_size=160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.63198,\t top1=86.2,\t top5=97.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:59<00:00,  1.22s/it, loss=0.635, top1=86.2, top5=97.6, img_size=160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.63480,\t top1=86.2,\t top5=97.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:02<00:00,  1.28s/it, loss=0.621, top1=86.5, top5=97.7, img_size=160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.62099,\t top1=86.5,\t top5=97.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:02<00:00,  1.27s/it, loss=0.611, top1=86.9, top5=97.8, img_size=160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.61075,\t top1=86.9,\t top5=97.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:02<00:00,  1.28s/it, loss=0.603, top1=86.9, top5=97.8, img_size=160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.60327,\t top1=86.9,\t top5=97.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:03<00:00,  1.29s/it, loss=0.596, top1=87.1, top5=97.9, img_size=160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.59561,\t top1=87.1,\t top5=97.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:00<00:00,  1.24s/it, loss=0.576, top1=87.2, top5=97.9, img_size=160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.57605,\t top1=87.2,\t top5=97.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:01<00:00,  1.25s/it, loss=0.567, top1=87.2, top5=97.9, img_size=160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.56722,\t top1=87.2,\t top5=97.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:03<00:00,  1.29s/it, loss=0.575, top1=87.7, top5=98, img_size=160]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.57495,\t top1=87.7,\t top5=98.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:01<00:00,  1.25s/it, loss=0.577, top1=87.6, top5=98, img_size=160]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.57651,\t top1=87.6,\t top5=98.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:02<00:00,  1.27s/it, loss=0.558, top1=87.4, top5=98, img_size=160]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.55809,\t top1=87.4,\t top5=98.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:08<00:00,  1.41s/it, loss=0.587, top1=87.4, top5=97.9, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.58691,\t top1=87.4,\t top5=97.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:02<00:00,  1.28s/it, loss=0.544, top1=87.8, top5=98.1, img_size=160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.54440,\t top1=87.8,\t top5=98.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:03<00:00,  1.29s/it, loss=0.552, top1=87.8, top5=98.1, img_size=160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.55189,\t top1=87.8,\t top5=98.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:01<00:00,  1.25s/it, loss=0.536, top1=88, top5=98.2, img_size=160]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.53611,\t top1=88.0,\t top5=98.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:04<00:00,  1.33s/it, loss=0.552, top1=88.3, top5=98.2, img_size=176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.55233,\t top1=88.3,\t top5=98.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:07<00:00,  1.38s/it, loss=0.568, top1=87.9, top5=98.1, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.56804,\t top1=87.9,\t top5=98.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:06<00:00,  1.35s/it, loss=0.55, top1=88.3, top5=98.3, img_size=192] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.54998,\t top1=88.3,\t top5=98.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:07<00:00,  1.37s/it, loss=0.544, top1=88.4, top5=98.2, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.54405,\t top1=88.4,\t top5=98.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:07<00:00,  1.38s/it, loss=0.542, top1=88.7, top5=98.2, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.54175,\t top1=88.7,\t top5=98.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:05<00:00,  1.34s/it, loss=0.54, top1=88.6, top5=98.3, img_size=192] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.54037,\t top1=88.6,\t top5=98.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:06<00:00,  1.35s/it, loss=0.532, top1=88.8, top5=98.3, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.53195,\t top1=88.8,\t top5=98.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:05<00:00,  1.33s/it, loss=0.525, top1=89, top5=98.4, img_size=192]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.52489,\t top1=89.0,\t top5=98.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:06<00:00,  1.36s/it, loss=0.504, top1=89, top5=98.4, img_size=192]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.50443,\t top1=89.0,\t top5=98.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:08<00:00,  1.40s/it, loss=0.509, top1=89, top5=98.5, img_size=192]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.50889,\t top1=89.0,\t top5=98.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:09<00:00,  1.41s/it, loss=0.499, top1=89.2, top5=98.4, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.49937,\t top1=89.2,\t top5=98.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:06<00:00,  1.36s/it, loss=0.485, top1=89.3, top5=98.5, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.48491,\t top1=89.3,\t top5=98.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:07<00:00,  1.37s/it, loss=0.485, top1=89.3, top5=98.5, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.48456,\t top1=89.3,\t top5=98.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:07<00:00,  1.38s/it, loss=0.486, top1=89.5, top5=98.5, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.48587,\t top1=89.5,\t top5=98.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:07<00:00,  1.37s/it, loss=0.482, top1=89.5, top5=98.5, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.48217,\t top1=89.5,\t top5=98.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:06<00:00,  1.35s/it, loss=0.471, top1=89.7, top5=98.5, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.47107,\t top1=89.7,\t top5=98.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:08<00:00,  1.40s/it, loss=0.465, top1=89.9, top5=98.6, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.46537,\t top1=89.9,\t top5=98.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:05<00:00,  1.34s/it, loss=0.461, top1=90, top5=98.6, img_size=192]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.46072,\t top1=90.0,\t top5=98.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:08<00:00,  1.39s/it, loss=0.466, top1=89.8, top5=98.6, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.46633,\t top1=89.8,\t top5=98.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:08<00:00,  1.40s/it, loss=0.46, top1=89.9, top5=98.6, img_size=192] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.45976,\t top1=89.9,\t top5=98.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:08<00:00,  1.39s/it, loss=0.471, top1=90.1, top5=98.7, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.47068,\t top1=90.1,\t top5=98.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:08<00:00,  1.40s/it, loss=0.462, top1=90.1, top5=98.7, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.46245,\t top1=90.1,\t top5=98.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:08<00:00,  1.40s/it, loss=0.462, top1=90.1, top5=98.7, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.46200,\t top1=90.1,\t top5=98.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:07<00:00,  1.37s/it, loss=0.46, top1=90.3, top5=98.7, img_size=192] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.46000,\t top1=90.3,\t top5=98.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:07<00:00,  1.38s/it, loss=0.456, top1=90.3, top5=98.8, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.45576,\t top1=90.3,\t top5=98.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:07<00:00,  1.38s/it, loss=0.456, top1=90.2, top5=98.7, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.45633,\t top1=90.2,\t top5=98.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:07<00:00,  1.38s/it, loss=0.457, top1=90.2, top5=98.7, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.45671,\t top1=90.2,\t top5=98.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:06<00:00,  1.36s/it, loss=0.454, top1=90.3, top5=98.8, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.45411,\t top1=90.3,\t top5=98.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:05<00:00,  1.34s/it, loss=0.452, top1=90.3, top5=98.8, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.45173,\t top1=90.3,\t top5=98.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:06<00:00,  1.35s/it, loss=0.447, top1=90.4, top5=98.8, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.44679,\t top1=90.4,\t top5=98.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:08<00:00,  1.40s/it, loss=0.45, top1=90.4, top5=98.8, img_size=192] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.44969,\t top1=90.4,\t top5=98.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:06<00:00,  1.36s/it, loss=0.442, top1=90.4, top5=98.8, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.44199,\t top1=90.4,\t top5=98.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:05<00:00,  1.34s/it, loss=0.467, top1=90, top5=98.7, img_size=176]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.46698,\t top1=90.0,\t top5=98.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:06<00:00,  1.35s/it, loss=0.433, top1=90.6, top5=98.8, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.43272,\t top1=90.6,\t top5=98.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:08<00:00,  1.40s/it, loss=0.441, top1=90.5, top5=98.8, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.44089,\t top1=90.5,\t top5=98.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:09<00:00,  1.42s/it, loss=0.446, top1=90.5, top5=98.8, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.44591,\t top1=90.5,\t top5=98.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:09<00:00,  1.42s/it, loss=0.437, top1=90.6, top5=98.8, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.43690,\t top1=90.6,\t top5=98.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:08<00:00,  1.40s/it, loss=0.435, top1=90.6, top5=98.8, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.43509,\t top1=90.6,\t top5=98.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:08<00:00,  1.40s/it, loss=0.44, top1=90.5, top5=98.8, img_size=192] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.44002,\t top1=90.5,\t top5=98.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:07<00:00,  1.38s/it, loss=0.445, top1=90.5, top5=98.8, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.44549,\t top1=90.5,\t top5=98.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:06<00:00,  1.36s/it, loss=0.439, top1=90.6, top5=98.8, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.43909,\t top1=90.6,\t top5=98.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:06<00:00,  1.36s/it, loss=0.44, top1=90.5, top5=98.8, img_size=192] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.43968,\t top1=90.5,\t top5=98.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:08<00:00,  1.40s/it, loss=0.441, top1=90.6, top5=98.8, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.44131,\t top1=90.6,\t top5=98.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:09<00:00,  1.41s/it, loss=0.44, top1=90.6, top5=98.8, img_size=192] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.44023,\t top1=90.6,\t top5=98.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:08<00:00,  1.41s/it, loss=0.438, top1=90.6, top5=98.8, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.43814,\t top1=90.6,\t top5=98.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:07<00:00,  1.38s/it, loss=0.44, top1=90.6, top5=98.8, img_size=192] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.44041,\t top1=90.6,\t top5=98.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:11<00:00,  1.45s/it, loss=0.435, top1=90.8, top5=98.9, img_size=208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.43467,\t top1=90.8,\t top5=98.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:13<00:00,  1.49s/it, loss=0.434, top1=90.8, top5=98.9, img_size=208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.43369,\t top1=90.8,\t top5=98.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:09<00:00,  1.42s/it, loss=0.434, top1=90.8, top5=98.9, img_size=208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.43408,\t top1=90.8,\t top5=98.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:11<00:00,  1.45s/it, loss=0.433, top1=90.7, top5=98.9, img_size=208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.43288,\t top1=90.7,\t top5=98.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:59<00:00,  2.43s/it, loss=0.433, top1=90.8, top5=98.9, img_size=208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.43277,\t top1=90.8,\t top5=98.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:09<00:00,  1.43s/it, loss=0.437, top1=90.7, top5=98.9, img_size=208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.43656,\t top1=90.7,\t top5=98.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:09<00:00,  1.42s/it, loss=0.431, top1=90.8, top5=98.9, img_size=208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.43149,\t top1=90.8,\t top5=98.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:10<00:00,  1.43s/it, loss=0.43, top1=90.8, top5=98.9, img_size=208] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.43030,\t top1=90.8,\t top5=98.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:11<00:00,  1.46s/it, loss=0.433, top1=90.8, top5=98.9, img_size=208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.43270,\t top1=90.8,\t top5=98.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:11<00:00,  1.46s/it, loss=0.434, top1=90.8, top5=98.9, img_size=208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.43418,\t top1=90.8,\t top5=98.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:14<00:00,  1.53s/it, loss=0.426, top1=90.9, top5=98.9, img_size=224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.42590,\t top1=90.9,\t top5=98.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:12<00:00,  1.48s/it, loss=0.432, top1=90.8, top5=98.9, img_size=208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.43189,\t top1=90.8,\t top5=98.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:13<00:00,  1.50s/it, loss=0.424, top1=91, top5=98.9, img_size=224]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.42436,\t top1=91.0,\t top5=98.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:15<00:00,  1.53s/it, loss=0.425, top1=90.9, top5=98.9, img_size=224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.42504,\t top1=90.9,\t top5=98.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:15<00:00,  1.54s/it, loss=0.426, top1=90.9, top5=98.9, img_size=224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.42595,\t top1=90.9,\t top5=98.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:13<00:00,  1.50s/it, loss=0.427, top1=90.9, top5=98.9, img_size=224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.42749,\t top1=90.9,\t top5=98.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:14<00:00,  1.51s/it, loss=0.423, top1=91, top5=98.9, img_size=224]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.42265,\t top1=91.0,\t top5=98.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:16<00:00,  1.57s/it, loss=0.426, top1=91, top5=98.9, img_size=224]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.42614,\t top1=91.0,\t top5=98.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:14<00:00,  1.51s/it, loss=0.422, top1=91, top5=98.9, img_size=224]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.42205,\t top1=91.0,\t top5=98.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:14<00:00,  1.52s/it, loss=0.422, top1=91, top5=98.9, img_size=224]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.42231,\t top1=91.0,\t top5=98.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:16<00:00,  1.55s/it, loss=0.426, top1=91, top5=98.9, img_size=224]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.42556,\t top1=91.0,\t top5=98.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:14<00:00,  1.53s/it, loss=0.422, top1=91.1, top5=99, img_size=224]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.42249,\t top1=91.1,\t top5=99.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:14<00:00,  1.52s/it, loss=0.423, top1=91.1, top5=99, img_size=224]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.42266,\t top1=91.1,\t top5=99.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:14<00:00,  1.52s/it, loss=0.428, top1=91, top5=98.9, img_size=224]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.42799,\t top1=91.0,\t top5=98.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:16<00:00,  1.56s/it, loss=0.421, top1=91.1, top5=98.9, img_size=224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.42122,\t top1=91.1,\t top5=98.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:16<00:00,  1.56s/it, loss=0.422, top1=91.1, top5=98.9, img_size=224]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.42174,\t top1=91.1,\t top5=98.9\n",
      "The generation of the probability tables took 02h47m17s to finish.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# start measuring time\n",
    "start_time = time.time()\n",
    "#----------------------------\n",
    "debug = True\n",
    "#debug = False\n",
    "if debug:\n",
    "    # loop for each candidate to form the ensemble\n",
    "    for idx, individual in enumerate(ofa2_nsga2[0:], 0):\n",
    "        encoding = individual.get('X')\n",
    "        model = individual_to_ofa(individual_to_arch([encoding], 20)[0])\n",
    "        filename = 'OFA2_model_' + str(idx).zfill(3)\n",
    "        path = os.path.join('ofa2_models_output_subset_50k', filename)\n",
    "        \n",
    "        # get classification label \n",
    "        top1 = ensemble_evaluate_ofa_subnet(\n",
    "            path,\n",
    "            ofa_network,\n",
    "            imagenet_data_path,\n",
    "            model,\n",
    "            data_loader_train_subset, # dataloader for the training set\n",
    "            batch_size=1_024,  # evaluation batch size\n",
    "            device=\"cuda:0\" if cuda_available else \"cpu\",\n",
    "        )\n",
    "#----------------------------\n",
    "# stop measuring time\n",
    "end_time = time.time()\n",
    "#----------------------------\n",
    "elapsed = end_time - start_time\n",
    "print('The generation of the probability tables took', time.strftime(\"%Hh%Mm%Ss\", time.gmtime(elapsed)), 'to finish.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of the notebook"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
