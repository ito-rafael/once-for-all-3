{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OFA³: Automatic Selection of the Best Non-dominated Sub-networks for Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Description**: \n",
    "  - This Jupyter notebook works as a preparation for the OFA³ search. \n",
    "  - We first load the 100 models obtained from the output of the OFA² search (file \"ofa2_nsga2.pickle\"). \n",
    "  - Then we take each model and evaluate them on the **<ins>validation set (50k images)</ins>** of the ILSVRC dataset (ImageNet-1k). \n",
    "  - The output of this notebook provides two tables for each model (200 tables in total):\n",
    "    - \"OFA2_model_XXX_class.csv\": table containing the top-5 predicted classes of the model.\n",
    "    - \"OFA2_model_XXX_prob.csv\": table containing the respective probabilities.\n",
    "  - The directory that files will be saved is **<ins>\"ofa2_models_output_val\"**</ins>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Author**: TBA (hidden due to blind review)\n",
    "- **email**: TBA (hidden due to blind review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **arXiv link**: TBA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q -r requirements.txt\n",
    "!pip install -q \\\n",
    "    numpy       \\\n",
    "    torch       \\\n",
    "    torchvision \\\n",
    "    ofa2        \\\n",
    "    tqdm        \\\n",
    "    matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# AI/ML/NN\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "# OFA/OFA²\n",
    "from ofa2.model_zoo import ofa_net\n",
    "from ofa2.imagenet_classification.elastic_nn.utils import set_running_statistics\n",
    "from ofa2.utils import AverageMeter#, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seeds for reproducibility\n",
    "random_seed = 1\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU.\n"
     ]
    }
   ],
   "source": [
    "# set device to use GPU or CPU\n",
    "cuda_available = torch.cuda.is_available()\n",
    "if cuda_available:\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    print(\"Using GPU.\")\n",
    "else:\n",
    "    print(\"Using CPU.\")\n",
    "#cuda0 = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rotKYovR6HsU",
    "outputId": "31a14141-3609-490e-abab-6ba9fef5ef5a",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ImageNet Full\n",
    "imagenet_data_path = \"~/dataset/imagenet/\"\n",
    "#----------------------------\n",
    "# ImageNet subset\n",
    "#imagenet_data_path = \"~/dataset/imagenet_1k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ofa_network = ofa_net(\"ofa_mbv3_d234_e346_k357_w1.2\", pretrained=True)\n",
    "# ofa_network2 = torch.load(model_dir='~/model/ofa_mbv3_d234_e346_k357_w1.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Ksze_r6G6HsV",
    "outputId": "d5b0e106-b7dc-4108-e9cb-f8287776bc18"
   },
   "outputs": [],
   "source": [
    "# The following function build the data transforms for test\n",
    "def build_val_transform(size):\n",
    "    return transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(int(math.ceil(size / 0.875))),\n",
    "            transforms.CenterCrop(size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imagenet_train = datasets.ImageFolder(root=os.path.join(imagenet_data_path, \"train\"), transform=build_val_transform(224))\n",
    "#imagenet_train_subset = datasets.ImageFolder(root=os.path.join(imagenet_data_path, \"train_subset_50k\"), transform=build_val_transform(224))\n",
    "imagenet_val = datasets.ImageFolder(root=os.path.join(imagenet_data_path, \"val\"), transform=build_val_transform(224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this dataloader is for the training set --> used to generate probability table\n",
    "#data_loader_train = torch.utils.data.DataLoader(\n",
    "#    datasets.ImageFolder(\n",
    "#        root=os.path.join(imagenet_data_path, \"train\"), transform=build_val_transform(224)\n",
    "#    ),\n",
    "#    batch_size=4_096, # evaluation batch size\n",
    "#    shuffle=False,    # evaluation only\n",
    "#    num_workers=16,   # number of workers for the data loader\n",
    "#    pin_memory=True,\n",
    "#    drop_last=False,\n",
    "#)\n",
    "#print(\"The ImageNet dataloader for the training set is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this dataloader is for the 50k subset of the training set --> used to generate probability table\n",
    "#data_loader_train_subset = torch.utils.data.DataLoader(\n",
    "#    datasets.ImageFolder(root=os.path.join(imagenet_data_path, \"train_subset_50k\"), transform=build_val_transform(224)),\n",
    "#    batch_size=1_024, # evaluation batch size\n",
    "#    shuffle=False,    # evaluation only\n",
    "#    num_workers=4,    # number of workers for the data loader\n",
    "#    pin_memory=True,\n",
    "#    drop_last=False,\n",
    "#)\n",
    "#print(\"The ImageNet dataloader for the training set is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ImageNet dataloader for the validation set is ready.\n"
     ]
    }
   ],
   "source": [
    "# this dataloader is for the validation set --> used to measure performance\n",
    "data_loader_val = torch.utils.data.DataLoader(\n",
    "    imagenet_val,\n",
    "    batch_size=1_024, # test batch size\n",
    "    shuffle=False,    # evaluation only\n",
    "    num_workers=8,    # number of workers for the data loader\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    ")\n",
    "print(\"The ImageNet dataloader for the validation set is ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load results from OFA²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ofa2_nsga2.pickle', 'rb') as f:\n",
    "    ofa2_nsga2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_evaluate_ofa_subnet(\n",
    "    filename, ofa_net, path, net_config, data_loader, batch_size, device=\"cuda:0\"\n",
    "):\n",
    "    assert \"ks\" in net_config and \"d\" in net_config and \"e\" in net_config\n",
    "    assert (\n",
    "        len(net_config[\"ks\"]) == 20\n",
    "        and len(net_config[\"e\"]) == 20\n",
    "        and len(net_config[\"d\"]) == 5\n",
    "    )\n",
    "    ofa_net.set_active_subnet(ks=net_config[\"ks\"], d=net_config[\"d\"], e=net_config[\"e\"])\n",
    "    subnet = ofa_net.get_active_subnet().to(device)\n",
    "    calib_bn(subnet, path, net_config[\"r\"][0], batch_size)\n",
    "    top1 = validate(filename, subnet, path, net_config[\"r\"][0], data_loader, batch_size, device)\n",
    "    return top1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calib_bn(net, path, image_size, batch_size, num_images=2000):\n",
    "    # print('Creating dataloader for resetting BN running statistics...')\n",
    "    dataset = datasets.ImageFolder(\n",
    "        os.path.join(path, \"train\"),\n",
    "        transforms.Compose(\n",
    "            [\n",
    "                transforms.RandomResizedCrop(image_size),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ColorJitter(brightness=32.0 / 255.0, saturation=0.5),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "                ),\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "    chosen_indexes = np.random.choice(list(range(len(dataset))), num_images)\n",
    "    sub_sampler = torch.utils.data.sampler.SubsetRandomSampler(chosen_indexes)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        sampler=sub_sampler,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    # print('Resetting BN running statistics (this may take 10-20 seconds)...')\n",
    "    set_running_statistics(net, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from: once-for-all/ofa/utils/common_tools.py\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    softmax = torch.nn.functional.softmax(output, dim=1)\n",
    "    # prob, pred = softmax.topk(maxk, 1, True, True)\n",
    "    prob, _ = softmax.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.reshape(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res, pred.t(), prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(filename, net, path, image_size, data_loader, batch_size=100, device=\"cuda:0\"):\n",
    "    if \"cuda\" in device:\n",
    "        net = torch.nn.DataParallel(net).to(device)\n",
    "    else:\n",
    "        net = net.to(device)\n",
    "\n",
    "    data_loader.dataset.transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(int(math.ceil(image_size / 0.875))),\n",
    "            transforms.CenterCrop(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    net.eval()\n",
    "    net = net.to(device)\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=len(data_loader), desc=\"Validate\") as t:\n",
    "            for i, (images, labels) in enumerate(data_loader):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                # compute output\n",
    "                output = net(images)\n",
    "                loss = criterion(output, labels)\n",
    "                #-----------------------------------------------------\n",
    "                # measure accuracy and record loss\n",
    "                res, pred, prob = accuracy(output, labels, topk=(1, 5))\n",
    "                acc1 = res[0]\n",
    "                acc5 = res[1]\n",
    "                # save to CSV\n",
    "                if filename is not None:\n",
    "                    # print(f'{acc1=}, {acc5=}, {pred}, {labels=}')\n",
    "                    labels_t = labels.t().unsqueeze(dim=1)\n",
    "                    topk_classification = torch.cat((pred, labels_t), dim=1)\n",
    "                    # cast to DataFrame\n",
    "                    topk_df = pd.DataFrame(topk_classification.cpu())\n",
    "                    topk_df.to_csv(filename + '_class.csv', mode='a', header=False, index=False)\n",
    "                    # probability\n",
    "                    topk_prob = pd.DataFrame(prob.cpu())\n",
    "                    topk_prob.to_csv(filename + '_prob.csv', encoding='utf-8', mode='a', header=False, index=False)\n",
    "                #-----------------------------------------------------\n",
    "                                \n",
    "                losses.update(loss.item(), images.size(0))\n",
    "                top1.update(acc1[0].item(), images.size(0))\n",
    "                top5.update(acc5[0].item(), images.size(0))\n",
    "                t.set_postfix(\n",
    "                    {\n",
    "                        \"loss\": losses.avg,\n",
    "                        \"top1\": top1.avg,\n",
    "                        \"top5\": top5.avg,\n",
    "                        \"img_size\": images.size(2),\n",
    "                    }\n",
    "                )\n",
    "                t.update(1)\n",
    "\n",
    "    print(\n",
    "        \"Results: loss=%.5f,\\t top1=%.1f,\\t top5=%.1f\"\n",
    "        % (losses.avg, top1.avg, top5.avg)\n",
    "    )\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def individual_to_arch(population, n_blocks):\n",
    "    archs = []\n",
    "    for individual in population:\n",
    "        archs.append(\n",
    "            {\n",
    "                \"ks\": individual[0:n_blocks],\n",
    "                \"e\": individual[n_blocks : 2 * n_blocks],\n",
    "                \"d\": individual[2 * n_blocks : -1],\n",
    "                \"r\": individual[-1:],\n",
    "            }\n",
    "        )\n",
    "    return archs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def individual_to_ofa(model):\n",
    "    # insert wid\n",
    "    model['wid'] = None\n",
    "    # cast back from NumPy to list\n",
    "    model['ks'] = model['ks'].tolist()\n",
    "    model['e'] = model['e'].tolist()\n",
    "    model['d'] = model['d'].tolist()\n",
    "    model['r'] = model['r'].tolist()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate probability table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:48<00:00,  1.00it/s, loss=1.33, top1=69.8, top5=89, img_size=160]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.32790,\t top1=69.8,\t top5=89.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:48<00:00,  1.01it/s, loss=1.33, top1=70, top5=89.2, img_size=160]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.32826,\t top1=70.0,\t top5=89.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:48<00:00,  1.01it/s, loss=1.31, top1=70.2, top5=89.4, img_size=160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.31150,\t top1=70.2,\t top5=89.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:43<00:00,  1.14it/s, loss=1.3, top1=70.3, top5=89.5, img_size=160] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.29972,\t top1=70.3,\t top5=89.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:48<00:00,  1.02it/s, loss=1.29, top1=70.6, top5=89.6, img_size=160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.28710,\t top1=70.6,\t top5=89.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:48<00:00,  1.02it/s, loss=1.27, top1=71, top5=89.8, img_size=160]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.27442,\t top1=71.0,\t top5=89.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:49<00:00,  1.02s/it, loss=1.27, top1=71, top5=89.9, img_size=160]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.26838,\t top1=71.0,\t top5=89.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:49<00:00,  1.00s/it, loss=1.26, top1=71.2, top5=89.9, img_size=160] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.25895,\t top1=71.2,\t top5=89.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:49<00:00,  1.01s/it, loss=1.25, top1=71.4, top5=90, img_size=160]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.25281,\t top1=71.4,\t top5=90.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:49<00:00,  1.00s/it, loss=1.23, top1=71.8, top5=90.2, img_size=160] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.22915,\t top1=71.8,\t top5=90.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:49<00:00,  1.00s/it, loss=1.23, top1=71.8, top5=90.2, img_size=160] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.23310,\t top1=71.8,\t top5=90.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:48<00:00,  1.01it/s, loss=1.21, top1=72.2, top5=90.6, img_size=160] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.20930,\t top1=72.2,\t top5=90.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:49<00:00,  1.00s/it, loss=1.21, top1=72.3, top5=90.5, img_size=160] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.21220,\t top1=72.3,\t top5=90.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:49<00:00,  1.00s/it, loss=1.21, top1=72.4, top5=90.7, img_size=160] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.20518,\t top1=72.4,\t top5=90.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:47<00:00,  1.04it/s, loss=1.21, top1=72.2, top5=90.6, img_size=160] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.20759,\t top1=72.2,\t top5=90.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:47<00:00,  1.02it/s, loss=1.19, top1=72.8, top5=90.8, img_size=160] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.18966,\t top1=72.8,\t top5=90.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:49<00:00,  1.00s/it, loss=1.19, top1=72.6, top5=90.8, img_size=160] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.19360,\t top1=72.6,\t top5=90.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:42<00:00,  1.16it/s, loss=1.17, top1=73.1, top5=91, img_size=160]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.16935,\t top1=73.1,\t top5=91.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:48<00:00,  1.01it/s, loss=1.17, top1=73.3, top5=91.1, img_size=160] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.16594,\t top1=73.3,\t top5=91.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:49<00:00,  1.01s/it, loss=1.15, top1=73.3, top5=91.2, img_size=160] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.14937,\t top1=73.3,\t top5=91.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:49<00:00,  1.01s/it, loss=1.14, top1=73.4, top5=91.3, img_size=160] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.13808,\t top1=73.4,\t top5=91.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:48<00:00,  1.00it/s, loss=1.15, top1=73.6, top5=91.3, img_size=160] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.14703,\t top1=73.6,\t top5=91.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:48<00:00,  1.01it/s, loss=1.15, top1=73.6, top5=91.4, img_size=160] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.14790,\t top1=73.6,\t top5=91.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:48<00:00,  1.02it/s, loss=1.13, top1=73.8, top5=91.4, img_size=160] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.12538,\t top1=73.8,\t top5=91.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:54<00:00,  1.11s/it, loss=1.15, top1=73.5, top5=91.3, img_size=192] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.15057,\t top1=73.5,\t top5=91.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:49<00:00,  1.01s/it, loss=1.11, top1=74, top5=91.6, img_size=160]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.11456,\t top1=74.0,\t top5=91.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:49<00:00,  1.01s/it, loss=1.12, top1=73.9, top5=91.6, img_size=160] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.12127,\t top1=73.9,\t top5=91.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:49<00:00,  1.01s/it, loss=1.1, top1=74.2, top5=91.7, img_size=160]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.10323,\t top1=74.2,\t top5=91.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:50<00:00,  1.03s/it, loss=1.11, top1=74.5, top5=91.8, img_size=176] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.10625,\t top1=74.5,\t top5=91.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:53<00:00,  1.10s/it, loss=1.12, top1=74.2, top5=91.7, img_size=192] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.12007,\t top1=74.2,\t top5=91.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:53<00:00,  1.10s/it, loss=1.11, top1=74.5, top5=91.8, img_size=192] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.10767,\t top1=74.5,\t top5=91.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:51<00:00,  1.05s/it, loss=1.1, top1=74.6, top5=91.9, img_size=192]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.09841,\t top1=74.6,\t top5=91.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:53<00:00,  1.09s/it, loss=1.1, top1=74.7, top5=92, img_size=192]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.09592,\t top1=74.7,\t top5=92.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:52<00:00,  1.06s/it, loss=1.1, top1=74.8, top5=91.9, img_size=192]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.09558,\t top1=74.8,\t top5=91.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:53<00:00,  1.09s/it, loss=1.08, top1=74.9, top5=92.1, img_size=192] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.08178,\t top1=74.9,\t top5=92.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:54<00:00,  1.10s/it, loss=1.07, top1=75.1, top5=92.2, img_size=192] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.07436,\t top1=75.1,\t top5=92.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:53<00:00,  1.09s/it, loss=1.05, top1=75.3, top5=92.4, img_size=192] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.05107,\t top1=75.3,\t top5=92.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:52<00:00,  1.07s/it, loss=1.05, top1=75.4, top5=92.4, img_size=192] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.05389,\t top1=75.4,\t top5=92.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:55<00:00,  1.13s/it, loss=1.04, top1=75.5, top5=92.5, img_size=192] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.04244,\t top1=75.5,\t top5=92.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:54<00:00,  1.11s/it, loss=1.03, top1=75.7, top5=92.6, img_size=192] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.02875,\t top1=75.7,\t top5=92.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:53<00:00,  1.09s/it, loss=1.03, top1=75.8, top5=92.6, img_size=192] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.02678,\t top1=75.8,\t top5=92.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:53<00:00,  1.10s/it, loss=1.03, top1=75.8, top5=92.6, img_size=192] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.02542,\t top1=75.8,\t top5=92.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:51<00:00,  1.05s/it, loss=1.02, top1=76, top5=92.7, img_size=192]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.02130,\t top1=76.0,\t top5=92.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:53<00:00,  1.09s/it, loss=1.01, top1=76.2, top5=92.9, img_size=192] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.01151,\t top1=76.2,\t top5=92.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:54<00:00,  1.11s/it, loss=1, top1=76.3, top5=92.9, img_size=192]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.00315,\t top1=76.3,\t top5=92.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:53<00:00,  1.10s/it, loss=1, top1=76.3, top5=93, img_size=192]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.00051,\t top1=76.3,\t top5=93.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:52<00:00,  1.07s/it, loss=1, top1=76.4, top5=93, img_size=192]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.00214,\t top1=76.4,\t top5=93.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:53<00:00,  1.10s/it, loss=0.997, top1=76.5, top5=93, img_size=192]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.99655,\t top1=76.5,\t top5=93.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:54<00:00,  1.11s/it, loss=1.01, top1=76.5, top5=93, img_size=192]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.00904,\t top1=76.5,\t top5=93.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:53<00:00,  1.10s/it, loss=1, top1=76.6, top5=93.1, img_size=192]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=1.00250,\t top1=76.6,\t top5=93.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:53<00:00,  1.09s/it, loss=0.992, top1=76.6, top5=93.2, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.99203,\t top1=76.6,\t top5=93.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:55<00:00,  1.12s/it, loss=0.997, top1=76.7, top5=93.2, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.99711,\t top1=76.7,\t top5=93.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:54<00:00,  1.11s/it, loss=0.994, top1=76.7, top5=93.2, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.99369,\t top1=76.7,\t top5=93.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:54<00:00,  1.12s/it, loss=0.991, top1=76.9, top5=93.2, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.99084,\t top1=76.9,\t top5=93.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:54<00:00,  1.11s/it, loss=0.989, top1=77, top5=93.2, img_size=192]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.98883,\t top1=77.0,\t top5=93.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:54<00:00,  1.11s/it, loss=0.987, top1=77, top5=93.3, img_size=192]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.98748,\t top1=77.0,\t top5=93.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:53<00:00,  1.10s/it, loss=0.985, top1=77, top5=93.3, img_size=192]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.98521,\t top1=77.0,\t top5=93.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:52<00:00,  1.06s/it, loss=0.977, top1=77.1, top5=93.3, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.97696,\t top1=77.1,\t top5=93.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:53<00:00,  1.09s/it, loss=0.978, top1=77.1, top5=93.4, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.97825,\t top1=77.1,\t top5=93.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:53<00:00,  1.09s/it, loss=0.975, top1=77.2, top5=93.4, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.97513,\t top1=77.2,\t top5=93.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:51<00:00,  1.06s/it, loss=0.995, top1=76.9, top5=93.2, img_size=176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.99523,\t top1=76.9,\t top5=93.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:53<00:00,  1.10s/it, loss=0.966, top1=77.3, top5=93.5, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.96557,\t top1=77.3,\t top5=93.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:53<00:00,  1.08s/it, loss=0.972, top1=77.3, top5=93.5, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.97240,\t top1=77.3,\t top5=93.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:52<00:00,  1.06s/it, loss=0.969, top1=77.3, top5=93.5, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.96860,\t top1=77.3,\t top5=93.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:54<00:00,  1.10s/it, loss=0.966, top1=77.4, top5=93.5, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.96611,\t top1=77.4,\t top5=93.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:53<00:00,  1.09s/it, loss=0.963, top1=77.4, top5=93.5, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.96341,\t top1=77.4,\t top5=93.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:54<00:00,  1.10s/it, loss=0.966, top1=77.4, top5=93.5, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.96618,\t top1=77.4,\t top5=93.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:55<00:00,  1.12s/it, loss=0.963, top1=77.4, top5=93.6, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.96271,\t top1=77.4,\t top5=93.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:54<00:00,  1.11s/it, loss=0.958, top1=77.5, top5=93.7, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.95822,\t top1=77.5,\t top5=93.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:54<00:00,  1.11s/it, loss=0.955, top1=77.5, top5=93.7, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.95476,\t top1=77.5,\t top5=93.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:55<00:00,  1.13s/it, loss=0.957, top1=77.6, top5=93.7, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.95717,\t top1=77.6,\t top5=93.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:54<00:00,  1.10s/it, loss=0.955, top1=77.6, top5=93.7, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.95535,\t top1=77.6,\t top5=93.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:55<00:00,  1.14s/it, loss=0.954, top1=77.5, top5=93.7, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.95413,\t top1=77.5,\t top5=93.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:54<00:00,  1.12s/it, loss=0.956, top1=77.5, top5=93.7, img_size=192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.95630,\t top1=77.5,\t top5=93.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:56<00:00,  1.16s/it, loss=0.941, top1=78.1, top5=93.9, img_size=208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.94062,\t top1=78.1,\t top5=93.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:56<00:00,  1.15s/it, loss=0.942, top1=77.9, top5=93.9, img_size=208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.94239,\t top1=77.9,\t top5=93.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:51<00:00,  1.04s/it, loss=0.941, top1=78, top5=93.9, img_size=208]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.94105,\t top1=78.0,\t top5=93.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:56<00:00,  1.15s/it, loss=0.939, top1=78.1, top5=94, img_size=208]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.93877,\t top1=78.1,\t top5=94.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:57<00:00,  1.17s/it, loss=0.937, top1=78, top5=94, img_size=208]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.93697,\t top1=78.0,\t top5=94.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:56<00:00,  1.15s/it, loss=0.932, top1=78.2, top5=94.1, img_size=208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.93250,\t top1=78.2,\t top5=94.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:55<00:00,  1.13s/it, loss=0.936, top1=78.1, top5=93.9, img_size=208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.93617,\t top1=78.1,\t top5=93.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:55<00:00,  1.14s/it, loss=0.931, top1=78.2, top5=94, img_size=208]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.93088,\t top1=78.2,\t top5=94.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:57<00:00,  1.17s/it, loss=0.935, top1=78.2, top5=94, img_size=208]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.93469,\t top1=78.2,\t top5=94.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:55<00:00,  1.13s/it, loss=0.937, top1=78.1, top5=94, img_size=208]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.93705,\t top1=78.1,\t top5=94.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:59<00:00,  1.21s/it, loss=0.919, top1=78.5, top5=94.1, img_size=224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.91900,\t top1=78.5,\t top5=94.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:56<00:00,  1.15s/it, loss=0.929, top1=78.2, top5=94.1, img_size=208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.92900,\t top1=78.2,\t top5=94.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:59<00:00,  1.22s/it, loss=0.916, top1=78.6, top5=94.2, img_size=224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.91603,\t top1=78.6,\t top5=94.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:52<00:00,  1.08s/it, loss=0.916, top1=78.6, top5=94.2, img_size=224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.91594,\t top1=78.6,\t top5=94.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:57<00:00,  1.17s/it, loss=0.918, top1=78.6, top5=94.1, img_size=224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.91792,\t top1=78.6,\t top5=94.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:59<00:00,  1.22s/it, loss=0.918, top1=78.6, top5=94.2, img_size=224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.91784,\t top1=78.6,\t top5=94.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:00<00:00,  1.24s/it, loss=0.912, top1=78.6, top5=94.2, img_size=224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.91168,\t top1=78.6,\t top5=94.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:58<00:00,  1.19s/it, loss=0.918, top1=78.5, top5=94.1, img_size=224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.91814,\t top1=78.5,\t top5=94.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:57<00:00,  1.18s/it, loss=0.912, top1=78.6, top5=94.2, img_size=224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.91227,\t top1=78.6,\t top5=94.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:59<00:00,  1.22s/it, loss=0.909, top1=78.7, top5=94.2, img_size=224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.90926,\t top1=78.7,\t top5=94.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:59<00:00,  1.21s/it, loss=0.912, top1=78.8, top5=94.2, img_size=224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.91237,\t top1=78.8,\t top5=94.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:58<00:00,  1.19s/it, loss=0.908, top1=78.9, top5=94.3, img_size=224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.90776,\t top1=78.9,\t top5=94.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:57<00:00,  1.17s/it, loss=0.907, top1=78.9, top5=94.3, img_size=224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.90686,\t top1=78.9,\t top5=94.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:58<00:00,  1.18s/it, loss=0.91, top1=78.8, top5=94.3, img_size=224] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.90994,\t top1=78.8,\t top5=94.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [00:58<00:00,  1.19s/it, loss=0.906, top1=78.8, top5=94.3, img_size=224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.90579,\t top1=78.8,\t top5=94.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 49/49 [01:00<00:00,  1.23s/it, loss=0.907, top1=78.9, top5=94.3, img_size=224]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.90664,\t top1=78.9,\t top5=94.3\n",
      "The generation of the probability tables took 03h49m06s to finish.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# start measuring time\n",
    "start_time = time.time()\n",
    "#----------------------------\n",
    "debug = True\n",
    "#debug = False\n",
    "if debug:\n",
    "    # loop for each candidate to form the ensemble\n",
    "    for idx, individual in enumerate(ofa2_nsga2[0:], 0):\n",
    "        encoding = individual.get('X')\n",
    "        model = individual_to_ofa(individual_to_arch([encoding], 20)[0])\n",
    "        filename = 'OFA2_model_' + str(idx).zfill(3)\n",
    "        path = os.path.join('ofa2_models_output_val', filename)\n",
    "        \n",
    "        # get classification label \n",
    "        top1 = ensemble_evaluate_ofa_subnet(\n",
    "            path,\n",
    "            ofa_network,\n",
    "            imagenet_data_path,\n",
    "            model,\n",
    "            data_loader_val, # dataloader for the training set\n",
    "            batch_size=1_024,  # evaluation batch size\n",
    "            device=\"cuda:0\" if cuda_available else \"cpu\",\n",
    "        )\n",
    "#----------------------------\n",
    "# stop measuring time\n",
    "end_time = time.time()\n",
    "#----------------------------\n",
    "elapsed = end_time - start_time\n",
    "print('The generation of the probability tables took', time.strftime(\"%Hh%Mm%Ss\", time.gmtime(elapsed)), 'to finish.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of the notebook"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
