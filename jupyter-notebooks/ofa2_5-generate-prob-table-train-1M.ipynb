{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OFA³: Automatic Selection of the Best Non-dominated Sub-networks for Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Description**: \n",
    "  - This Jupyter notebook works as a preparation for the OFA³ search. \n",
    "  - We first load the 100 models obtained from the output of the OFA² search (file \"ofa2_nsga2.pickle\"). \n",
    "  - Then we take each model and evaluate them on the **<ins>training set (1,281,167 images)</ins>** of the ILSVRC dataset (ImageNet-1k). \n",
    "  - The output of this notebook provides two tables for each model (200 tables in total):\n",
    "    - \"OFA2_model_XXX_class.csv\": table containing the top-5 predicted classes of the model.\n",
    "    - \"OFA2_model_XXX_prob.csv\": table containing the respective probabilities.\n",
    "  - The directory that files will be saved is <ins>**\"ofa2_models_output\"</ins>**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Author**: TBA (hidden due to blind review)\n",
    "- **email**: TBA (hidden due to blind review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **arXiv link**: TBA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q -r requirements.txt\n",
    "!pip install -q \\\n",
    "    numpy       \\\n",
    "    torch       \\\n",
    "    torchvision \\\n",
    "    ofa2        \\\n",
    "    tqdm        \\\n",
    "    matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# AI/ML/NN\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "# OFA/OFA²\n",
    "from ofa2.model_zoo import ofa_net\n",
    "from ofa2.imagenet_classification.elastic_nn.utils import set_running_statistics\n",
    "from ofa2.utils import AverageMeter#, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seeds for reproducibility\n",
    "random_seed = 1\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU.\n"
     ]
    }
   ],
   "source": [
    "# set device to use GPU or CPU\n",
    "cuda_available = torch.cuda.is_available()\n",
    "if cuda_available:\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    print(\"Using GPU.\")\n",
    "else:\n",
    "    print(\"Using CPU.\")\n",
    "#cuda0 = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rotKYovR6HsU",
    "outputId": "31a14141-3609-490e-abab-6ba9fef5ef5a",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ImageNet Full\n",
    "imagenet_data_path = \"~/dataset/imagenet/\"\n",
    "#----------------------------\n",
    "# ImageNet subset\n",
    "#imagenet_data_path = \"~/dataset/imagenet_1k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ofa_network = ofa_net(\"ofa_mbv3_d234_e346_k357_w1.2\", pretrained=True)\n",
    "# ofa_network2 = torch.load(model_dir='~/model/ofa_mbv3_d234_e346_k357_w1.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Ksze_r6G6HsV",
    "outputId": "d5b0e106-b7dc-4108-e9cb-f8287776bc18"
   },
   "outputs": [],
   "source": [
    "# The following function build the data transforms for test\n",
    "def build_val_transform(size):\n",
    "    return transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(int(math.ceil(size / 0.875))),\n",
    "            transforms.CenterCrop(size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ImageNet dataloader for the training set is ready.\n"
     ]
    }
   ],
   "source": [
    "# this dataloader is for the training set --> used to generate probability table\n",
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(\n",
    "        root=os.path.join(imagenet_data_path, \"train\"), transform=build_val_transform(224)\n",
    "    ),\n",
    "    batch_size=4_096, # evaluation batch size\n",
    "    shuffle=False,    # evaluation only\n",
    "    num_workers=16,   # number of workers for the data loader\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    ")\n",
    "print(\"The ImageNet dataloader for the training set is ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load results from OFA²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ofa2_nsga2.pickle', 'rb') as f:\n",
    "    ofa2_nsga2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_evaluate_ofa_subnet(\n",
    "    filename, ofa_net, path, net_config, data_loader, batch_size, device=\"cuda:0\"\n",
    "):\n",
    "    assert \"ks\" in net_config and \"d\" in net_config and \"e\" in net_config\n",
    "    assert (\n",
    "        len(net_config[\"ks\"]) == 20\n",
    "        and len(net_config[\"e\"]) == 20\n",
    "        and len(net_config[\"d\"]) == 5\n",
    "    )\n",
    "    ofa_net.set_active_subnet(ks=net_config[\"ks\"], d=net_config[\"d\"], e=net_config[\"e\"])\n",
    "    subnet = ofa_net.get_active_subnet().to(device)\n",
    "    calib_bn(subnet, path, net_config[\"r\"][0], batch_size)\n",
    "    top1 = validate(filename, subnet, path, net_config[\"r\"][0], data_loader, batch_size, device)\n",
    "    return top1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calib_bn(net, path, image_size, batch_size, num_images=2000):\n",
    "    # print('Creating dataloader for resetting BN running statistics...')\n",
    "    dataset = datasets.ImageFolder(\n",
    "        os.path.join(path, \"train\"),\n",
    "        transforms.Compose(\n",
    "            [\n",
    "                transforms.RandomResizedCrop(image_size),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ColorJitter(brightness=32.0 / 255.0, saturation=0.5),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "                ),\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "    chosen_indexes = np.random.choice(list(range(len(dataset))), num_images)\n",
    "    sub_sampler = torch.utils.data.sampler.SubsetRandomSampler(chosen_indexes)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        sampler=sub_sampler,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    # print('Resetting BN running statistics (this may take 10-20 seconds)...')\n",
    "    set_running_statistics(net, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from: once-for-all/ofa/utils/common_tools.py\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    softmax = torch.nn.functional.softmax(output, dim=1)\n",
    "    # prob, pred = softmax.topk(maxk, 1, True, True)\n",
    "    prob, _ = softmax.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.reshape(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res, pred.t(), prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(filename, net, path, image_size, data_loader, batch_size=100, device=\"cuda:0\"):\n",
    "    if \"cuda\" in device:\n",
    "        net = torch.nn.DataParallel(net).to(device)\n",
    "    else:\n",
    "        net = net.to(device)\n",
    "\n",
    "    data_loader.dataset.transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(int(math.ceil(image_size / 0.875))),\n",
    "            transforms.CenterCrop(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    net.eval()\n",
    "    net = net.to(device)\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=len(data_loader), desc=\"Validate\") as t:\n",
    "            for i, (images, labels) in enumerate(data_loader):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                # compute output\n",
    "                output = net(images)\n",
    "                loss = criterion(output, labels)\n",
    "                #-----------------------------------------------------\n",
    "                # measure accuracy and record loss\n",
    "                res, pred, prob = accuracy(output, labels, topk=(1, 5))\n",
    "                acc1 = res[0]\n",
    "                acc5 = res[1]\n",
    "                # save to CSV\n",
    "                if filename is not None:\n",
    "                    # print(f'{acc1=}, {acc5=}, {pred}, {labels=}')\n",
    "                    labels_t = labels.t().unsqueeze(dim=1)\n",
    "                    topk_classification = torch.cat((pred, labels_t), dim=1)\n",
    "                    # cast to DataFrame\n",
    "                    topk_df = pd.DataFrame(topk_classification.cpu())\n",
    "                    topk_df.to_csv(filename + '_class.csv', mode='a', header=False, index=False)\n",
    "                    # probability\n",
    "                    topk_prob = pd.DataFrame(prob.cpu())\n",
    "                    topk_prob.to_csv(filename + '_prob.csv', encoding='utf-8', mode='a', header=False, index=False)\n",
    "                #-----------------------------------------------------\n",
    "                                \n",
    "                losses.update(loss.item(), images.size(0))\n",
    "                top1.update(acc1[0].item(), images.size(0))\n",
    "                top5.update(acc5[0].item(), images.size(0))\n",
    "                t.set_postfix(\n",
    "                    {\n",
    "                        \"loss\": losses.avg,\n",
    "                        \"top1\": top1.avg,\n",
    "                        \"top5\": top5.avg,\n",
    "                        \"img_size\": images.size(2),\n",
    "                    }\n",
    "                )\n",
    "                t.update(1)\n",
    "\n",
    "    print(\n",
    "        \"Results: loss=%.5f,\\t top1=%.1f,\\t top5=%.1f\"\n",
    "        % (losses.avg, top1.avg, top5.avg)\n",
    "    )\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def individual_to_arch(population, n_blocks):\n",
    "    archs = []\n",
    "    for individual in population:\n",
    "        archs.append(\n",
    "            {\n",
    "                \"ks\": individual[0:n_blocks],\n",
    "                \"e\": individual[n_blocks : 2 * n_blocks],\n",
    "                \"d\": individual[2 * n_blocks : -1],\n",
    "                \"r\": individual[-1:],\n",
    "            }\n",
    "        )\n",
    "    return archs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def individual_to_ofa(model):\n",
    "    # insert wid\n",
    "    model['wid'] = None\n",
    "    # cast back from NumPy to list\n",
    "    model['ks'] = model['ks'].tolist()\n",
    "    model['e'] = model['e'].tolist()\n",
    "    model['d'] = model['d'].tolist()\n",
    "    model['r'] = model['r'].tolist()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate probability table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 313/313 [08:18<00:00,  1.59s/it, loss=0.759, top1=83.3, top5=96.6, img_size=160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.75945,\t top1=83.3,\t top5=96.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 313/313 [08:07<00:00,  1.56s/it, loss=0.751, top1=83.4, top5=96.7, img_size=160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.75109,\t top1=83.4,\t top5=96.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 313/313 [08:02<00:00,  1.54s/it, loss=0.74, top1=83.8, top5=96.8, img_size=160] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.73967,\t top1=83.8,\t top5=96.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 313/313 [08:31<00:00,  1.63s/it, loss=0.73, top1=83.9, top5=96.8, img_size=160] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.72951,\t top1=83.9,\t top5=96.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 313/313 [08:47<00:00,  1.69s/it, loss=0.714, top1=84.3, top5=97, img_size=160]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.71428,\t top1=84.3,\t top5=97.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 313/313 [08:42<00:00,  1.67s/it, loss=0.706, top1=84.5, top5=97, img_size=160]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.70575,\t top1=84.5,\t top5=97.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 313/313 [08:44<00:00,  1.67s/it, loss=0.699, top1=84.7, top5=97.1, img_size=160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.69878,\t top1=84.7,\t top5=97.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 313/313 [08:20<00:00,  1.60s/it, loss=0.695, top1=84.8, top5=97.1, img_size=160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.69531,\t top1=84.8,\t top5=97.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 313/313 [08:48<00:00,  1.69s/it, loss=0.686, top1=85, top5=97.2, img_size=160]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.68590,\t top1=85.0,\t top5=97.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 313/313 [08:10<00:00,  1.57s/it, loss=0.672, top1=85.2, top5=97.2, img_size=160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.67200,\t top1=85.2,\t top5=97.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 313/313 [08:45<00:00,  1.68s/it, loss=0.669, top1=85.4, top5=97.3, img_size=160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.66918,\t top1=85.4,\t top5=97.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 313/313 [08:36<00:00,  1.65s/it, loss=0.661, top1=85.6, top5=97.4, img_size=160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.66077,\t top1=85.6,\t top5=97.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 313/313 [08:36<00:00,  1.65s/it, loss=0.656, top1=85.8, top5=97.4, img_size=160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.65649,\t top1=85.8,\t top5=97.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 313/313 [08:35<00:00,  1.65s/it, loss=0.646, top1=86, top5=97.5, img_size=160]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.64614,\t top1=86.0,\t top5=97.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 313/313 [08:29<00:00,  1.63s/it, loss=0.643, top1=86, top5=97.5, img_size=160]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: loss=0.64345,\t top1=86.0,\t top5=97.5\n"
     ]
    }
   ],
   "source": [
    "# start measuring time\n",
    "start_time = time.time()\n",
    "#----------------------------\n",
    "debug = True\n",
    "#debug = False\n",
    "if debug:\n",
    "    # loop for each candidate to form the ensemble\n",
    "    for idx, individual in enumerate(ofa2_nsga2[:], 0):\n",
    "        encoding = individual.get('X')\n",
    "        model = individual_to_ofa(individual_to_arch([encoding], 20)[0])\n",
    "        filename = 'OFA2_model_' + str(idx).zfill(3)\n",
    "        path = os.path.join('ofa2_models_output', filename)\n",
    "        \n",
    "        # get classification label \n",
    "        top1 = ensemble_evaluate_ofa_subnet(\n",
    "            path,\n",
    "            ofa_network,\n",
    "            imagenet_data_path,\n",
    "            model,\n",
    "            data_loader_train, # dataloader for the training set\n",
    "            batch_size=4_096,  # evaluation batch size\n",
    "            device=\"cuda:0\" if cuda_available else \"cpu\",\n",
    "        )\n",
    "#----------------------------\n",
    "# stop measuring time\n",
    "end_time = time.time()\n",
    "#----------------------------\n",
    "elapsed = end_time - start_time\n",
    "print('The generation of the probability tables took', time.strftime(\"%Hh%Mm%Ss\", time.gmtime(elapsed)), 'to finish.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of the notebook"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
